


// В литературе можно найти множество различных подходов к зада-
// че SLAM с использованием разных типов сенсоров: лидары, сонары,
// камеры [6], в данной работе речь идет об однокамерном SLAM. Од-
// нокамерный SLAM - область компьютерного зрения, применяемая в
// робототехнике для автономной навигации и составления карты местно-
// сти по видео изображению с одной камеры (в отличии от стерео SLAM,
// где используется две камеры). 
// Один из подходов однокамерного SLAM
// заключается в том, что из изображения извлекаются так называемые
// особые точки (feature points), положение которых затем отслеживают-
// ся на последующих изображениях - таким образом формируются тре-
// ки проекций особых точек. Имея данные о проекциях особой точки на
// изображения и данные о положении камеры, в момент взятия этих изоб-
// ражений, можно решить 
// задачу вычисления пространственных коорди-
// нат материальной точки, которую можно трактовать как известную в
// более широком смысле задачу bundle adjustment

== SLAM, применение, описание контекста, интро


== ORB SLAM - моно слам


описание процедуры Bundle Adjustment (BA)

// tag::related_work[]


Bundle Adjustment, как известно, обеспечивает точные оценки местоположения камеры, а также разреженную геометрическую реконструкцию [1, 2], учитывая, что обеспечивается сильная сеть совпадений и хорошие начальные предположения. Долгое время такой подход считался недоступным для приложений реального времени, таких как визуальная одновременная локализация и отображение (Visual SLAM).
Визуальный SLAM имеет цель оценить траекторию камеры при реконструкции окружающей среды. В настоящее время мы знаем, что для достижения точных результатов при непомерно высоких вычислительных затратах алгоритм SLAM в реальном времени должен обеспечивать BA:

- Соответствующие наблюдения за функциями сцены (точки карты) среди подмножества выбранных кадров (ключевых кадров). Поскольку сложность растет с увеличением количества ключевых кадров, при их выборе следует избегать ненужной избыточности.
- Сильная сетевая конфигурация ключевых кадров и точек для получения точных результатов, то есть хорошо распределенный набор ключевых кадров, наблюдающих точки со значительным параллаксом и с большим количеством совпадений замыкания цикла.
- Первоначальная оценка положений ключевых кадров и местоположений точек для нелинейной оптимизации.
- Местная карта в исследовании, где оптимизация направлена ​​на достижение масштабируемости.
- Возможность выполнять быструю глобальную оптимизацию (например, граф позы) для закрытия циклов в реальном времени.

Первым применением BA в реальном времени была работа Mouragon et. al. [3], за которой последовала новаторская работа Кляйна и Мюррея по SLAM [4], известная как Parallel Tracking and Mapping (PTAM). Этот алгоритм, хотя и ограничен мелкомасштабными операциями, предоставляет простые, но эффективные методы для выбора ключевых кадров, сопоставления функций, точечной триангуляции, локализации камеры для каждого кадра и перемещения после сбоя отслеживания. К сожалению, несколько факторов серьезно ограничивают его применение: отсутствие закрытия цикла и адекватной обработки окклюзий, низкая инвариантность с точки зрения перемещения и необходимость вмешательства человека для начальной загрузки карты.

В этой работе мы опираемся на основные идеи PTAM, работу по распознаванию мест Гальвеса-Лопеса и Тардоса [5], замыкание цикла с учетом масштаба, выполненное Strasdat et. al [6] и использование информации о совместимости для крупномасштабных операций [7, 8] для разработки с нуля ORB-SLAM, новой монокулярной системы SLAM, основные вклады которой:

- Использование одних и тех же функций для всех задач: отслеживание, отображение, перемещение и закрытие цикла. Это делает нашу систему более эффективной, простой и надежной. 

Алгоритм использует функции ORB (oriented FAST & rotated BRIEF) [9], которые позволяют работать в реальном времени без графических процессоров, обеспечивая хорошую инвариантность к изменениям точки обзора и освещения.
- Работа в реальном времени в больших средах. Благодаря использованию графа совместимости, отслеживание и отображение сосредоточены в локальной видимой области, независимо от размера глобальной карты.
- Закрытие цикла в реальном времени на основе оптимизации графа позы, который мы называем Essential Graph. Он построен из остовного дерева, поддерживаемого системой, ссылок замыкания цикла и сильных ребер из графа ковидимости.
- Перемещение камеры в реальном времени со значительной инвариантностью к точке обзора и освещению. Это позволяет восстановиться после сбоя отслеживания, а также улучшает повторное использование карты.
- Новая автоматическая и надежная процедура инициализации, основанная на выборе модели, которая позволяет создавать начальную карту плоских и неплоских сцен.
- Выживание наиболее подходящего подхода к выбору точек карты и ключевых кадров, который щедр при порождении, но очень ограничен при отбраковке. Эта политика улучшает надежность отслеживания и увеличивает срок службы, поскольку избыточные ключевые кадры отбрасываются.


// tag::related_work[]

// tag::Bundle_Adjustment[]



=== Bundle_Adjustment
Bundle Adjustment (BA) is known to provide accurate estimates of camera localizations as well as a sparse geometrical reconstruction [1, 2], given that a strong network of matches and good initial guesses are provided. For long time this approach was considered unaffordable for real time applications such as Visual Simultaneous Localisation and Mapping (Visual SLAM). 
Visual SLAM has the goal of estimating the camera trajectory while reconstructing the environment. Nowadays we know that to achieve accurate results at non-prohibitive computational cost, a real time SLAM algorithm has to provide BA with:

- Corresponding observations of scene features (map points) among a subset of selected frames (keyframes). As complexity grows with the number of keyframes, their selection should avoid unnecessary redundancy. 
- A strong network configuration of keyframes and points to produce accurate results, that is, a well spread set of keyframes observing points with significant parallax and with plenty of loop closure matches. 
- An initial estimation of the keyframe poses and point locations for the non-linear optimization. 
- A local map in exploration where optimization is focused to achieve scalability. 
- The ability to perform fast global optimizations (e.g. pose graph) to close loops in real-time.

The first real time application of BA was the visual odometry work of Mouragon et. al. [3], followed by the ground breaking SLAM work of Klein and Murray [4], known as Parallel Tracking and Mapping (PTAM). This algorithm, while limited to small scale operation, provides simple but effective methods for keyframe selection, feature matching, point triangulation, camera localization for every frame, and relocalization after tracking failure. Unfortunately several factors severely limit its application: lack of loop closing and adequate handling of occlusions, low invariance to viewpoint of the relocalization and the need of human intervention for map bootstrapping.

In this work we build on the main ideas of PTAM, the place recognition work of Gálvez-López and Tardós [5], the scale-aware loop closing of Strasdat et. al [6] and the use of covisibility information for large scale operation [7, 8], to design from scratch ORB-SLAM, a novel monocular SLAM system whose main contributions are:

- Use of the same features for all tasks: tracking, mapping, relocalization and loop closing. This makes our system more efficient, simple and reliable. We use ORB features [9] which allow real-time performance without GPUs, providing good invariance to changes in viewpoint and illumination.
- Real time operation in large environments. Thanks to the use of a covisibility graph, tracking and mapping is focused in a local covisible area, independent of global map size.
- Real time loop closing based on the optimization of a pose graph that we call the Essential Graph. It is built from a spanning tree maintained by the system, loop closure links and strong edges from the covisibility graph.
- Real time camera relocalization with significant invariance to viewpoint and illumination. This allows recovery from tracking failure and also enhances map reuse.
- A new automatic and robust initialization procedure based on model selection that permits to create an initial map of planar and non-planar scenes.
- A survival of the fittest approach to map point and keyframe selection that is generous in the spawning but very restrictive in the culling. This policy improves tracking robustness, and enhances lifelong operation because redundant keyframes are discarded.
// end::Bundle_Adjustment[]

Ii-a Place Recognition 
// tag::place_recognition[]
The survey by Williams et al. [13] compared several approaches for place recognition and concluded that techniques based on appearance, that is image to image matching, scale better in large environments than map to map or image to map methods. Within appearance based methods, bags of words techniques [14], such as the probabilistic approach FAB-MAP [15], are to the fore because of their high efficiency. DBoW2 [5] used for the first time bags of binary words obtained from BRIEF descriptors [16] along with the very efficient FAST feature detector [17]. This reduced in more than one order of magnitude the time needed for feature extraction, compared to SURF [18] and SIFT [19] features that were used in bags of words approaches so far. Although the system demonstrated to be very efficient and robust, the use of BRIEF, neither rotation nor scale invariant, limited the system to in-plane trajectories and loop detection from similar viewpoints. In our previous work [11], we proposed a bag of words place recognizer built on DBoW2 with ORB [9]. ORB are binary features invariant to rotation and scale (in a certain range), resulting in a very fast recognizer with good invariance to viewpoint. We demonstrated the high recall and robustness of the recognizer in four different datasets, requiring less than 39ms (including feature extraction) to retrieve a loop candidate from a 10K image database. In this work we use an improved version of that place recognizer, using covisibility information and returning several hypotheses when querying the database instead of just the best match.
// end::place_recognition[]

Ii-B Map Initialization 
// tag::Map_Initialization[]


Monocular SLAM requires a procedure to create an initial map because depth cannot be recovered from a single image. One way to solve the problem is to initially track a known structure [20]. In the context of filtering approaches, points can be initialized with high uncertainty in depth using an inverse depth parametrization [21], which hopefully will later converge to their real positions. The recent semi-dense work of Engel et al. [10], follows a similar approach initializing the depth of the pixels to a random value with high variance.

Initialization methods from two views either assumes locally scene planarity [4, 22] and recover the relative camera pose from a homography using the method of Faugeras et. al [23], or compute an essential matrix [24, 25] that models planar and general scenes, using the five-point algorithm of Nister [26], which requires to deal with multiple solutions. Both reconstruction methods are not well constrained under low parallax and suffer from a twofold ambiguity solution if all points of a planar scene are closer to one of the camera centers [27]. On the other hand if a non-planar scene is seen with parallax a unique fundamental matrix can be computed with the eight-point algorithm [2] and the relative camera pose can be recovered without ambiguity.

We present in Section IV a new automatic approach based on model selection between a homography for planar scenes and a fundamental matrix for non-planar scenes. A statistical approach to model selection was proposed by Torr et al. [28]. Under a similar rationale we have developed a heuristic initialization algorithm that takes into account the risk of selecting a fundamental matrix in close to degenerate cases (i.e. planar, nearly planar, and low parallax), favoring the selection of the homography. In the planar case, for the sake of safe operation, we refrain from initializing if the solution has a twofold ambiguity, as a corrupted solution could be selected. We delay the initialization until the method produces a unique solution with significant parallax.

// end::Map_Initialization[]

Ii-C Monocular SLAM 
// tag::Monocular_SLAM[]

filtering approach

keyframe-based approaches

// Monocular SLAM was initially solved by filtering [20, 29, 30, 21]. In that approach every frame is processed by the filter to jointly estimate the map feature locations and the camera pose. It has the drawbacks of wasting computation in processing consecutive frames with little new information and the accumulation of linearization errors. On the other hand keyframe-based approaches [3, 4] estimate the map using only selected frames (keyframes) allowing to perform more costly but accurate bundle adjustment optimizations, as mapping is not tied to frame-rate. Strasdat et. al [31] demonstrated that keyframe-based techniques are more accurate than filtering for the same computational cost.

// features: FAST corners matched by patch correlation

// The most representative keyframe-based SLAM system is probably PTAM by Klein and Murray [4]. It was the first work to introduce the idea of splitting camera tracking and mapping in parallel threads, and demonstrated to be successful for real time augmented reality applications in small environments. The original version was later improved with edge features, a rotation estimation step during tracking and a better relocalization method [32]. The map points of PTAM correspond to FAST corners matched by patch correlation. This makes the points only useful for tracking but not for place recognition. In fact PTAM does not detect large loops, and the relocalization is based on the correlation of low resolution thumbnails of the keyframes, yielding a low invariance to viewpoint.

// motion-only BA, and a back-end based on sliding-window BA
// loop closing with 7DoF pose graph optimization
// the Essential Graph

// Strasdat et. al [6] presented a large scale monocular SLAM system with a front-end based on optical flow implemented on a GPU, followed by FAST feature matching and motion-only BA, and a back-end based on sliding-window BA. Loop closures were solved with a pose graph optimization with similarity constraints (7DoF), that was able to correct the scale drift appearing in monocular SLAM. From this work we take the idea of loop closing with 7DoF pose graph optimization and apply it to the Essential Graph defined in Section III-D

// covisibility graph
// frame-rate relocalization and loop detection, loop closing

// Strasdat et. al [7] used the front-end of PTAM, but performed the tracking only in a local map retrieved from a covisibility graph. They proposed a double window optimization back-end that continuously performs BA in the inner window, and pose graph in a limited-size outer window. However, loop closing is only effective if the size of the outer window is large enough to include the whole loop. In our system we take advantage of the excellent ideas of using a local map based on covisibility, and building the pose graph from the covisibility graph, but apply them in a totally redesigned front-end and back-end. Another difference is that, instead of using specific features for loop detection (SURF), we perform the place recognition on the same tracked and mapped features, obtaining robust frame-rate relocalization and loop detection.


// loop closing, relocalization

// Pirker et. al [33] proposed CD-SLAM, a very complete system including loop closing, relocalization, large scale operation and efforts to work on dynamic environments. However map initialization is not mentioned. The lack of a public implementation does not allow us to perform a comparison of accuracy, robustness or large-scale capabilities.

// orb is more general system, have global relocalization, loop closing and reuse the map

// The visual odometry of Song et al. [34] uses ORB features for tracking and a temporal sliding window BA back-end. In comparison our system is more general as they do not have global relocalization, loop closing and do not reuse the map. They are also using the known distance from the camera to the ground to limit monocular scale drift.

LSD-SLAM, large scale semi-dense maps, using direct methods, semi-dense map, with more potential applications for robotics than the sparse output generated by feature-based SLAM.
camera localization accuracy is significantly lower than in our system and PTAM

// The recent work of Engel et. al [10], known as LSD-SLAM, is able to build large scale semi-dense maps, using direct methods (i.e. optimization directly over image pixel intensities) instead of bundle adjustment over features. Their results are very impressive as the system is able to operate in real time, without GPU acceleration, building a semi-dense map, with more potential applications for robotics than the sparse output generated by feature-based SLAM. Nevertheless they still need features for loop detection and their camera localization accuracy is significantly lower than in our system and PTAM, as we show experimentally in Section VIII-B. This surprising result is discussed in Section IX-B.

quadracopters: Without requiring to extract features in every frame they are able to operate at high frame-rates semi-direct visual odometry SVO of Forster [22].

// In a halfway between direct and feature-based methods is the semi-direct visual odometry SVO of Forster et al. [22]. Without requiring to extract features in every frame they are able to operate at high frame-rates obtaining impressive results in quadracopters. However no loop detection is performed and the current implementation is mainly thought for downward looking cameras.

keyframe selection: cost-effective approach(PTAM)/robustness(ORB_SLAM)

// Finally we want to discuss about keyframe selection. All visual SLAM works in the literature agree that running BA with all the points and all the frames is not feasible. The work of Strasdat et al. [31] showed that the most cost-effective approach is to keep as much points as possible, while keeping only non-redundant keyframes. The PTAM approach was to insert keyframes very cautiously to avoid an excessive growth of the computational complexity. This restrictive keyframe insertion policy makes the tracking fail in hard exploration conditions. Our survival of the fittest strategy achieves unprecedented robustness in difficult scenarios by inserting keyframes as quickly as possible, and removing later the redundant ones, to avoid the extra cost.


// end::Monocular_SLAM[]

difference betw Monocular_SLAM and stereo_slam


Iii System Overview 

// tag::ORB_SLAM_System_Overview[]


// end::ORB_SLAM_System_Overview[]




Iii-a Feature Choice 
// tag::Feature_Choice[]
One of the main design ideas in our system is that the same features used by the mapping and tracking are used for place recognition to perform frame-rate relocalization and loop detection. This makes our system efficient and avoids the need to interpolate the depth of the recognition features from near SLAM features as in previous works [6, 7]. We requiere features that need for extraction much less than 33ms per image, which excludes the popular SIFT (∼300ms) [19], SURF (∼300ms) [18] or the recent A-KAZE (∼100ms) [35]. To obtain general place recognition capabilities, we require rotation invariance, which excludes BRIEF [16] and LDB [36].

We chose ORB [9], which are oriented multi-scale FAST corners with a 256 bits descriptor associated. They are extremely fast to compute and match, while they have good invariance to viewpoint. This allows to match them from wide baselines, boosting the accuracy of BA. We already shown the good performance of ORB for place recognition in [11]. While our current implementation make use of ORB, the techniques proposed are not restricted to these features.
// end::Feature_Choice[]

Iii-B Three Threads: Tracking, Local Mapping and Loop Closing 
// tag::ORB_SLAM_Threads[]

.ORB-SLAM system overview, showing all the steps performed by the tracking, local mapping and loop closing threads. The main components of the place recognition module and the map are also shown.
image::4-12-2021-14-25-22-PM.png[] 




Our system, see an overview in Fig. 1, incorporates three threads that run in parallel: tracking, local mapping and loop closing. The tracking is in charge of localizing the camera with every frame and deciding when to insert a new keyframe. We perform first an initial feature matching with the previous frame and optimize the pose using motion-only BA. If the tracking is lost (e.g. due to occlusions or abrupt movements), the place recognition module is used to perform a global relocalization. Once there is an initial estimation of the camera pose and feature matchings, a local visible map is retrieved using the covisibility graph of keyframes that is maintained by the system, see Fig. 2(a) and Fig. 2(b). Then matches with the local map points are searched by reprojection, and camera pose is optimized again with all matches. Finally the tracking thread decides if a new keyframe is inserted. All the tracking steps are explained in detail in Section V. The novel procedure to create an initial map is presented in Section IV.

The local mapping processes new keyframes and performs local BA to achieve an optimal reconstruction in the surroundings of the camera pose. New correspondences for unmatched ORB in the new keyframe are searched in connected keyframes in the covisibility graph to triangulate new points. Some time after creation, based on the information gathered during the tracking, an exigent point culling policy is applied in order to retain only high quality points. The local mapping is also in charge of culling redundant keyframes. We explain in detail all local mapping steps in Section VI.

The loop closing searches for loops with every new keyframe. If a loop is detected, we compute a similarity transformation that informs about the drift accumulated in the loop. Then both sides of the loop are aligned and duplicated points are fused. Finally a pose graph optimization over similarity constraints [6] is performed to achieve global consistency. The main novelty is that we perform the optimization over the Essential Graph, a sparser subgraph of the covisibility graph which is explained in Section III-D. The loop detection and correction steps are explained in detail in Section VII.

We use the Levenberg-Marquardt algorithm implemented in g2o [37] to carry out all optimizations. In the Appendix we describe the error terms, cost functions, and variables involved in each optimization.


// end::ORB_SLAM_Threads[]


Iii-C Map Points, KeyFrames and their Selection 

// tag::snippets[]
// end::snippets[]


=== описание основных элементов, обработка данных


== ORB SLAM 2 - стерео, глубина, описать изменения


=== описание изменений, как работать со стерео,


=== сравнение с аналогами


=== применение


== ORB SLAM 3


=== что поменялось


=== метрики


== результаты, вывод


Abstract
// This paper presents ORB-SLAM, a feature-based monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation.


С. Отслеживание и составление карт

Слежение и картографирование используют схему в Визуально-инерциальном монокулярном SLAM с повторным использованием карты.

    Поток отслеживания оптимизирует только состояние последних двух кадров, а положение точки на карте остается неизменным.
    При сопоставлении используется скользящее окно ключевых кадров и их точек в качестве оптимизируемых переменных, включая ключевые кадры, которые можно просматривать вместе, но сохранять их фиксированными.

В некоторых случаях, когда медленное движение не может обеспечить хорошие возможности наблюдения за инерционными параметрами, инициализация может не привести к точному решению в течение 15 секунд. Чтобы сделать систему более устойчивой, в этой статье предлагается новый метод оптимизации масштаба. Этот метод основан на улучшенном методе оптимизации одноинерциальной навигации, в котором вставляются все ключевые кадры, но единственными оценочными параметрами являются масштаб и направление силы тяжести ( Рисунок 2г). В данном случае ошибочное предположение о том, что предубеждения остаются неизменными. Расчетное значение каждого кадра можно использовать для исправления смещений. Расчетная эффективность этой оптимизации очень высока. Он выполняется в потоке локального сопоставления каждые 10 секунд, пока сопоставление не превысит 100 ключевых кадров или пока инициализация не превысит 75 секунд.

In some cases, when slow motion cannot provide good inertial parameter observation capabilities, initialization may not converge to an accurate solution within 15 seconds. In order to make the system more robust, this paper proposes aNew scale optimization methodThis method is based on an improved single-inertial navigation optimization method, in which all key frames are inserted, but scale and gravity direction are the only estimated parameters (Figure 2d). In this case, it is an incorrect assumption that biases remain unchanged. The estimated value of each frame can be used to correct biases. The calculation efficiency of this optimization is very high. It is executed in the local mapping thread every 10 seconds until the mapping exceeds 100 key frames, or the initialization exceeds 75 seconds.

D. Устойчивое снижение потерь при отслеживании

Система VIO, описанная в этой статье, переходит в состояние отказа визуального отслеживания, когда система отслеживает менее 15 точек, а затем выполняет:

    Кратковременный сбой: используйте показания IMU для оценки позы, спроецируйте точки карты на предполагаемую позу камеры, а затем выполните сопоставление в большом окне изображения, и результат сопоставления будет включен в оптимизацию VIO. В большинстве случаев визуальное отслеживание можно восстановить, но если оно превышает 5 секунд, оно не восстанавливается. Перейти в следующее состояние.

    Длительный сбой: повторно инициализируйте визуальную инерциальную навигацию, чтобы построить карту, и эта карта станет активной.

The VIO system of this article enters the state of visual tracking failure when the system tracks less than 15 points, and then executes:

Short-term failure: use the IMU reading to estimate the pose, project the map points onto the estimated camera pose, and then do the matching in a large image window, and the matching result is included in the VIO optimization.

Long-term failure: re-initialize the visual inertial navigation to build a map, and this map becomes the active map.


Слияние карт и обнаружение замкнутого цикла

Краткосрочные и среднесрочные ассоциации данных, установленные между фреймом изображения и активной картой, используются в потоке отслеживания и сопоставления для проецирования точек карты на предполагаемую позу, а затем сопоставляются в небольшом окне для получения взаимосвязи сопоставления. ORB-SLAM - это модель мешка слов, предназначенная для долговременной ассоциации данных для перемещения и обнаружения замкнутого цикла.
В отличие от отслеживания, в распознавании местоположения используется DBoW2 для создания базы данных ключевых кадров с использованием его вектора пакета слов, и данное изображение запроса может эффективно предоставить наиболее похожий ключевой кадр в соответствии с его набором слов. Используя только первый кадр-кандидат, исходный запрос DBoW2 может достичь 50-80% точности и отзыва. Чтобы предотвратить ложноположительные наблюдения, DBoW2 реализует проверки временной и геометрической согласованности, чтобы повысить точность рабочей точки до 100% и скорость отзыва до 30-40%. Очень важно, чтобы проверка согласованности времени задерживала распознавание позиции как минимум на 3 ключевых кадра. При попытке использовать его в нашей системе Атлас мы обнаружили, что эта задержка и низкая скорость отзыва часто возникают в повторяющихся областях одной и той же или разных карт.
В работе этой статьи мы предлагаем новый алгоритм повторного распознавания сцены, который улучшает скорость отзыва, когда она связана со смешанными данными карты в течение длительного времени. Когда поток сопоставления отфильтровывает ключевой кадр, повторное распознавание сцены пытается обнаружить ключевой кадр в Атласе для сопоставления. Если согласованный ключевой кадр находится в активной карте, это определяет замкнутый цикл; в противном случае это ассоциация данных гибридной карты, и выполняется объединение согласованной карты и текущей активной карты. Вторая особенность этого метода заключается в том, что после оценки поз текущего кадра и согласованного кадра карты мы строим частичное окно между согласованным кадром и соседними с ним кадрами в общем виде. В этом окне мы сосредоточены на поиске временной ассоциации данных,тем самым повышая точность обнаружения замкнутого контура и слияния карт.
A. Повторная идентификация сцены

Для достижения высокой скорости отзыва каждый новый ключевой кадр будет использовать базу данных DBoW2 для обнаружения нескольких похожих ключевых кадров в Altas. Для достижения 100% точности. Каждый фрейм-кандидат должен быть геометрически выверен. Геометрическая проверка включает в себя проверку того, существует ли особая точка ORB (расстояние Хэмминга), соответствующая дескриптору точки карты в окне изображения. Если есть несколько подходящих кадров-кандидатов, сначала удалите неправильное совпадение, а также необходимо сравнить соотношение расстояний со вторым кадром-кандидатом. Процесс повторного распознавания сцены выглядит следующим образом:

    Ключевые кадры-кандидаты DBoW2: используйте активные ключевые кадры для извлечения трех кадров-кандидатов из базы данных DBoW2 Altas, включая K а К_а Ka​Фрейм общего вида, мы называем совпадающим фреймом. K м Км Kм。
    Частичное окно: для каждого K м Км KмМы определяем частичное окно, включающее K м Км KмЛучшая общая рамка обзора с ним и все точки карты, которые они наблюдали. Прямой индекс DBoW2 обеспечивает K а К_а Ka​Сопоставляя характерные точки ключевого кадра локального окна, мы можем получить соответствие между 2D-2D и 3D-3D.
    Преобразование трехмерного выравнивания: используйте RANSAC-> Т а м T_ {am} ТмЧтобы лучше выровнять локальное окно K м Км Kмс участием K а К_а Ka​Точка на карте. В монокулярной или монокулярной инерциальной системе навигации, если карта не была успешно инициализирована, мы вычисляем преобразование Sim3, и если инициализация прошла успешно, мы вычисляем преобразование SE3. При вычислении двух преобразований мы используем трехточечный алгоритм Горна для нахождения Тэма. Если рассчитанный Tam равен K а К_а KаЕсли точка в км преобразуется в км, ошибка перепроецирования меньше определенного порога, и совпадение считается правильным. Выбирается гипотеза, набравшая наибольшее количество голосов (при условии, что гипотеза соответствует определенному порогу).
    Оптимизация сопоставления: преобразуйте все точки карты в локальном окне с помощью Tam, чтобы найти больше точек карты, которые соответствуют ключевым точкам в Ka. В то же время K а К_а KаПереключитесь в локальное окно, чтобы найти подходящую точку. Используйте все совпадающие точки для вычисления Tam и используйте двунаправленную нелинейную оптимизацию с надежной функцией ядра для ошибки перепроецирования для оптимизации Tam. Если количество переходов превышает определенный порог после оптимизации, она будет выполняться в меньшем окне изображения. Сопоставление и нелинейная оптимизация второго этапа.
    Проверка в трех ключевых кадрах общего представления: чтобы избежать ложноположительных результатов, DBoW2 решает, запускать ли, задерживать или повторно распознавать потерянные позиции в трех последовательных ключевых кадрах. Ключ к этому методу: в большинстве случаев информация, которую нам нужно проверить, уже есть на карте. Чтобы проверить местоположение и повторную идентификацию, нам необходимо проверить местоположение на активной карте. K а К_а KаДва ключевых кадра общего вида (точки карты общего вида в кадре общего вида превышают определенный порог. Если такой ключевой кадр общего вида не найден, проверка будет выполнена в новом ключевом кадре, но есть Нет необходимости начинать заново. Мешок слов. Проверка продолжается до тех пор, пока не останется три ключевых кадра для проверки. Т а м T_ {am} Тм, Или проверка двух последовательных ключевых кадров не удалась.
    Проверка направления гравитации: в случае IMU, если активная карта является зрелой, мы уже оценили Т а м T_ {am} Тм. Нам нужно убедиться, что углы тангажа и крена двух кадров ниже определенного порога, чтобы определить, выполнять ли повторную идентификацию положения.

Б. Визуальное слияние карт

При успешном повторном распознавании позиции создается ключевой кадр в активной карте Ma. K а К_а KаИ ключевой кадр на карте Altas Mm K м Км Kмиспользовать Т м а T_ {ma} ТмВыполните ассоциацию данных гибридной карты, чтобы объединить карту. Здесь следует отметить, что информация о карте в Altas должна повторно использоваться потоком отслеживания, чтобы избежать дублирования карты. Положи сюда M а М_а MаКарта к M м М_м MмНа карте для справки, потому что M а М_а MаВ нем много компонентов, и может потребоваться некоторое время, чтобы все слились. Слияние карт разделено на две части: во-первых, в K а К_а Kас участием K м Км KмОбъединение выполняется в окне соединения, определяемом соседними точками. На втором этапе коррекция распространяется на остальную часть объединенного изображения посредством оптимизации карты позы. Конкретные шаги алгоритма слияния:

    Коллекция окон подключения: окно подключения включает K а К_а KаКлючевой кадр общего с ним видения, K м Км KмИ его общий ключевой кадр обзора, и все точки карты, которые они наблюдали. использовать Т м а T_ {ma} ТмСтавить M а М_а MаТочки карты и ключевые кадры в M м М_м MмВыровняйте и разместите в окне подключения.
    Карта слияния: M а М_а Mас участием M м М_м MмFusion формирует новую активную карту. Чтобы удалить повторяющиеся точки, в M м М_м MмАктивный поиск по ключевым кадрам в M а М_а MаОчки матча, удалять для каждого матча M а М_а MаУкажите, M м М_м MмТочки сохраняют все наблюдения. Используйте среднесрочную корреляцию точек, чтобы обновить общее видение и добавить базовую карту M м М_м Mмс участием M а М_а MаСоединительный край.
    БА в окне подключения: поместите все данные из M м М_м Mмс участием M а М_а MаКлючевые кадры оптимизированы локально. Чтобы обеспечить количество ключевых кадров в скользящем окне, M м М_м MмРамка общего обзора остается неизменной. После завершения оптимизации все фреймы в окне подключения можно отслеживать для быстрого и точного повторного использования карты. M м М_м Mм。
    Оптимизация карты позы: используйте карту сущности всей карты слияния, чтобы оптимизировать карту позы и сохранить фиксированный ключевой кадр области соединения. Эта оптимизация распространяет поправку из окна подключения на остальную часть карты.

C. Визуальная инерциальная навигационная карта слияния

Шаги алгоритма визуально-инерционного слияния аналогичны шагам чистого визуального слияния. Улучшите шаги 1 и 3 в чистом зрении, чтобы лучше использовать инерционную информацию:

    Коллекция окон соединения VI: если активный объект зрелый, используйте карту Ma перед включением Ma в окно соединения Т м а T_ {ma} Тм(SE3) Выполните преобразование. Если активный не созрел, используйте Т м а T_ {ma} Тм(Sim3) для выравнивания M а М_а Mа。
    Окно подключения VI BA: активный ключевой кадр K а К_а KаА также можно оптимизировать позу, скорость и смещение последних пяти ключевых кадров. Эти переменные коррелируют посредством предварительной интеграции IMU. за M м М_м MмИ мы тоже правы K м Км KмОптимизируйте позу, скорость и смещение пяти соседних кадров в его хронометраж, как показано на следующем рисунке:
    
    за M м М_м Mм, Содержит ключевой кадр непосредственно перед частичным окном, но фиксирован; и для M а М_а Mа, Содержит похожие ключевые кадры, но его позу можно оптимизировать. Все точки, которые можно увидеть во всех ключевых кадрах, и позы ключевых кадров для наблюдения за этими точками также были оптимизированы. Используйте ошибку перепроецирования, чтобы связать ключевой кадр с ключевой точкой.
D. Обнаружение замкнутого контура

Обнаружение замкнутого цикла похоже на объединение карт, но оба ключевых кадра повторной идентификации сцены находятся под активной картой. Окно соединения формируется в соответствии с согласованными ключевыми кадрами, и повторяющиеся точки обнаруживаются и объединяются, а затем строятся новые ребра в общем виде и в основном графе. Затем оптимизируйте карту позы, чтобы распространить результаты коррекции с обратной связью на остальные карты. Последним шагом является глобальный BA, и оценка MAP получается после рассмотрения среднесрочного и долгосрочного сопоставления обнаружения замкнутого контура. В случае визуальной инерциальной навигации она выполняется только тогда, когда количество ключевых кадров ниже порогового значения, чтобы избежать огромных вычислительных затрат.



from 
https://medium.com/@j.zijlmans/lsd-slam-vs-orb-slam2-a-literature-based-comparison-20732df431d


The algorithms works on three threads, a tracking thread, a local mapping thread and a loop closing thread.
Initializing the map

To initialize the map starting by computing the relative pose between two scenes, they compute two geometrical models in parallel, one for a planar scene, a homography and one for non-planar scenes, a fundamental matrix. They then choose one of both based on a relative score of both. Using the selected model they estimate multiple motion hypotheses and en see if one is significantly better then the others, if so, a full bundle adjustment is done, otherwise the initialization starts over.
Tracking

The tracking part localizes the camera and decides when to insert a new keyframe. Features are matched with the previous frame and the pose is optimized using motion-only bundle adjustment. The features extracted are FAST corners. (for res. till 752x480, 1000 corners should be good, for higher (KITTI 1241x376) 2000 corners works). Multiple scale-levels (factor 1.2) are used and each level is divided into a grid in which 5 corners per cell are attempted to be extracted. These FAST corners are then described using ORB. The initial pose is estimated using a constant velocity motion model. If the tracking is lost, the place recognition module kicks in and tries to re-localize itself. When there is an estimation of the pose and feature matches, the co-visibility graph of keyframes, that is maintained by the system, is used to get a local visible map. This local map consists of keyframes that share map point with the current frame, the neighbors of these keyframes and a reference keyframe which share the most map points with the current frame. Through re-projection, matches of the local map are searched on the frame and the camera pose is optimized using these matches. Finally is decided if a new Keyframe needs to be created, new keyframes are inserted very frequently to make tracking more robust. A new keyframe is created when at least 20 frames has passed from the last keyframe, and last global re-localization, the frame tracks at least 50 points of which less then 90% are point from the reference keyframe.
Local mapping

First the new keyframe is inserted into the covisibility graph, the spanning tree linking a keyframe to the keyframe with the most points in common, and a 'bag of words' representation of the keyframe (used for data association for triangulating new points) is created.

New map points are created by triangulating ORB from connected keyframes in the covisibility graph. The unmachted ORB in a keyframe are compared with other unmatched ORB in other keyframes. The match must fulfill the epipolare constraint to be valid. To be a match, the ORB pairs are triangulated and checked if in both frames they have a positive depth, and the parallax, re projection error and scale consistency is checked. Then the match is projected to other connected keyframes to check if it is also in these.

The new map points first need to go through a test to increase the likelihood of these map points being valid. They need to be found in more than 25 % of the frames in which it is predicted to be visible and it must be observed by at least three keyframes.

Then through local bundle adjustment, the current keyframe, all keyframes connected to it through the co-visibility graph and all the map points seen by these keyframes are optimized using the keyframes that do see the map points but are not connected to the current keyframe.

Finally keyframes that are abundent are discarded to remain a certain simplicity. Keyframes from which more than 90 % of the map points can be seen by three other keyframes in the same scale-level are discarded.
Loop closing

To detect possible loops, they check bag of words vectors of the current keyframe and its neighbors in the covisibitlity graph. The min. simularity of these bag of words vectors is taken as a benchmark and from all the keyframes with a bag of words simulatrity to the current key frame that is greater that this benchmark, all the keyframes that are allready connected to the current keyframe are removed. If three loop canditates that are consistant are detected consecutively, this loop is regarded as a serious candiddate.

For these loops, the similarity transformation is calculated (7DOF, 3 trans, 3 rot, 1 scale) RANSAC itterations are prformed to find them and these are then optimized after which more correspondences are searched and then again an optimization is preformed. If the similarity is supported by having enough inlier's, the loop is accepted.

The current keyframe pose in then adjusted and this is propagated to its neighbors and the corresponding map-points are fused. Finally a pose graph optimization is preformed over the essential graph to take out the loop closure created errors along the graph. This also corrects for scale drift.

.ORB-SLAM3 EUROC Dataset Test pure mono
image:1-12-2021-13-22-48-PM.png[] 



https://www.programmersought.com/article/46859005831/