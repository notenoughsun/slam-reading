= DeepSLAM неконтролируемая монокулярная SLAM-система на основе глубокого обучения без учителя 

:imagesdir: images
:toc: preamble

:author: timur chikichev
:email: t.chikichev@navigine.ru

:pygments-style: Coderay

:toc: macro


Недавно методы, основанные на глубоком обучении (DL), продемонстрировали многообещающую эффективность при оценке позы и глубины [9], [10]. Большинство из них учатся на необработанных изображениях с ограниченным учетом геометрических моделей, которые были хорошо поняты за эти годы и признаны основами визуальных SLAM-систем. Однако было продемонстрировано, что обучающее представление для оценки глубины более эффективно, если соблюдаются геометрические ограничения [11]. Поэтому интересно посмотреть, как обучающее представление может быть эффективно использовано для визуального SLAM, беспрепятственно объединяя знания, накопленные за десятилетия в геометрических моделях. Как совместить геометрические модели и ограничения с сетевой архитектурой и функцией потерь, все еще остается сложной и открытой проблемой. Геометрические ограничения связаны с движением эго и структурой окружающей среды, что означает, что они могут быть использованы при проектировании пространственно-временных фотометрических потерь и геометрических потерь для методов, основанных на DL. Неправильное использование геометрических ограничений в функции потерь может привести к плохой производительности оценки или, что еще хуже, несовпадению процесса обучения. Напротив, надлежащее использование может привести к повышению точности оценки в среде обучения без учителя.
Большинство методов на основе DL основаны на схемах обучения с учителем, для которых требуются наборы данных с аннотированной достоверной информацией. Однако пометить большие объемы данных сложно и дорого, что ограничивает возможные сценарии применения методов на основе DL. Это особенно верно в контексте визуального SLAM, потому что роботы обычно работают в совершенно неизвестной среде. Более того, для визуальной SLAM-системы очень интересно обучаться по неконтролируемой схеме, так что производительность может постоянно улучшаться за счет увеличения размера наборов данных без аннотированной наземной истины.

DeepSLAM, алгоритм визуальной одновременной локализации и навигации (SLAM), неконтролируемая монокулярная SLAM-система на основе глубокого обучения (DL) без учителя (unsupervised-learning).

image:4-12-2021-12-17-45-PM.png[] 
(а) Схема архитектуры DeepSLAM. Он принимает монокулярные цветные изображения в качестве входных данных и создает карты глубины, позы и облака точек в качестве выходных данных с помощью Mapping-Net, Tracking-Net и Loop-Net. Mapping-Net - это сеть автоэнкодер для оценки глубины. 
Tracking-Net - это архитектура на основе RCNN для оценки позы. 
Loop-Net - это сеть построенная по арзитектуре CNN для обнаружения замыкания петель. Построение и оптимизация графа поз реализованы в качестве back-end. (b) DeepSLAM демонстрирует высокую производительность в некоторых сложных сценах.


DeepSLAM работает в полностью автоматическом режиме и не требует предварительной разметки данных. Для работы этого алгоритма требуется только стерео образы вместо задания данных о положении камеры для каждого изображения, таким образом алгоритм реализует концепцию SLAM, самостоятельно определяя координату и дополняя карту. В качестве входных данных принимается последовательность монокулярных изображений. Таким образом, это реализация монокулярной концепции SLAM. 

DeepSLAM состоит из нескольких основных компонентов которые разделены на модуль построения карты, модуль локализации, модуль замыкания циклов и дополнительно модуль оптимизации графа. 

В частности, модуль построения карты(Mapping-Net) построен по архитектуре энкодер-декодера и используется описания трехмерной структуры окружающей среды.

// Specifically, the Mapping-Net is an encoder and decoder architecture for describing the 3-D structure of environment, whereas the Tracking-Net is a recurrent convolutional neural network architecture for capturing the camera motion. 
// The Loop-Net is a pretrained binary clas- sifier for detecting loop closures. DeepSLAM can simulta- neously generate pose estimate, depth map, and outlier re- jection mask. 
// In this article, we evaluate its performance on various datasets, and find that DeepSLAM achieves good performance in terms of pose estimation accuracy, and is robust in some challenging scenes.

Модуль локализации (Tracking-Net) построен на рекурррентной сверточной нейронной сети (RCNN) и предназначен для определения движения камеры. 
Модуль замыкания циклов (Loop-Net) - это предварительно обученный бинарный классификатор для обнаружения замыканий петель. 
DeepSLAM одновременно определяет координату камеры, строит карту глубины сцены и маска для фильтрации шума. 

DeepSLAM обеспечивает хорошую производительность с точки зрения точности оценки позы, и надежен в некоторых сложных сценах.


// Training scheme of the proposed DeepSLAM system. 


// We use stereo images to train the system in order to recover the scale information of the environment, which is similar to ones used in training. 
// The spatial image losses between a stereo image pair and the temporal image losses between a sequence image pair are formulated to train the networks. 
// The error map produced from the system is used as the loss masks for outlier rejection. 
// The uncertainty produced from the system is also used to train the networks.

Схема обучения предлагаемой системы DeepSLAM:

Система обучается на стереоизображениях, чтобы сохранить масштаб в сцене. При монокулярном SLAM невозможно с самого начала учитывать масштаб на изображении, системы SLAM умеют корректировать карту при получении необходимых данных и определении масштаба. Вместо это DeepSLAM ограничивается на работу со стерео данными. Предположительно, можно с незначительными затратами адаптировать систему для работы с внешним источником инофрмации о глубине сцены. Пока что можно рассматривать DeepSLAM как систему для работы только со стереоданными.

DeepSLAM восстанавливает инфрормацию о масштабе окружающей среды, аналогичную той, которая была использована при обучении.

DeepSLAM формулирет пространственные функции невязки/разницы между парой стереоизображений и соответственно временные функции для сравненния между парами изображений в последовательности.
Пространственно-временные ограничения используются для для обучения сетей в DeepSLAM.
Система определяет карту ошибок, которая далее используется в качестве масок потерь для фильтрации выбросов. Неопределенность, создаваемая системой, также используется в качестве веса для минимизации энергии системы при обучении сетей.

Система не требует большой объем аннотированных данных для обучения сетей что снимает ограничения на выполнение обучения.

1) DeepSLAM - система визуального SLAM, основанная на неконтролируемом глубоком обучении. Метод использует комбинацию глубокого обучения и геометрических ограничений.
2) Глубокая рекуррентная сверточная нейронная сеть (RCNN) предназначена для моделирования движения камеры/объекта путем использования как пространственных, так и временных свойств последовательности стереоизображений во время обучения.
3) DeepSLAM объединяет результат отслеживания на основе DL и обнаружение замыкания цикла с механизмом оптимизации на основе графиков, формируя полную визуальную систему SLAM.
4) Погрешность метода контролируется функцией ошибки и неопределенностью каждого состояния, определяемой из карт ошибок геометрической и фотометрической согласованности. Это повышает надежность работы DeepSLAM в сложных условиях.


Хотя DeepSLAM использует стереосистему для обучения, для тестирования требуется только монокулярное зрение. Таким образом, DeepSLAM представляет собой монокулярную визуальную SLAM-систему.

== Другие работы SLAM на основе глубокого обучения

=== Локализация на основе методов глубокого обучения с учителем


Хорошо известно, что сверточные нейронные сети (CNN) успешны в классификации объектов. Новая идея - использовать
CNN для регрессии позы. Kendall et al. [9] предложил архитектуру PoseNet для решения задачи локализации в постановке задачи регресси с помощью CNN. 
Система была обучена с набором данных с известными реальными координатами и мог использоваться для сценариев с возможностью разрыва в локализации и повторной релокализации.

В работе [12] расширили PoseNet, включив в систему дополнительную нейронную сеть, чтобы повысить производительность релокализации (определение координаты по набору измерений и карте без известной начальной точки маршрута) в сложных условиях. В работе [13] в PoseNet был добавлен модуль для длительного использования  краткосрочной пространственной памяти (LSTM) для повышения производительности. 
Чтобы оценить неопределенность оценки позы, Кендалл и Чиполла [14] предложили байесовскую сеть PoseNet, рассматривая отсев в сети как средство выборки. 
Кларк и др. [15] предложили использовать рекуррентную сеть RCNN для реализации регрессии позы с видеоклипами, принимая во внимание временную информацию.

Помимо регрессии позы, движение эго между двумя кадрами изображения можно было оценить с помощью DL, вдохновленного стереогеометрическими моделями. Costante et al. [16] разработали CNN для оценки движения эго с контролируемым обучением. Mohanty et al. [17] использовали CNN для оценки преобразования между двумя последовательными кадрами. Wang et al. [18], [19] обучили RCNN оценивать движение камеры. Мелехов и др. [20] представили систему относительной оценки положения камеры с помощью CNN. 
Oliveira et al. [21] построили метрическую сеть для оценки движения и положения камеры, и топологическую сеть для оценки топологического местоположения. Затем прогнозы этих двух сетей соединяются путем последовательной оптимизации.

Ummenhofer et al. [22] предложили «DeMoN» для одновременной оценки положения камеры, оценки глубины изображения, определения нормалей к поверхностям и оптического потока в кадре, но для работы системе требовались известные достоверные данные. 
DeTone et al. [23] реализовали одну сеть для предсказания местоположения характерных точек и другую сеть для вычисления гомографии с данными, синтезированными вручную. Вместо описанной выше сквозной оценки позы с помощью CNN, Tateno et al. [24] использовали CNN для оценки карты глубины, а затем использовали систему SLAM на основе геометрической модели для выполнения оценки позы. 
В работе [25] были объединены методы прогнозирования глубины на основе CNN с ORB-SLAM [5], чтобы преодолеть проблему масштабирования для монокулярных систем SLAM. Ji et al. [26] объединили разреженные точки карты из системы SLAM и плотные предсказанные карты из CNN, чтобы работать с границами глубины в трехмерной реконструкции (не с неопределенными весами в нейронной сети, поскольку для них нельзя явно задать геометрические ограничения). 
Laidlow et al. [27] предложили систему трехмерной реконструкции под названием Deepfusion. Они представили карты предсказанной плотной глубины в ORB-SLAM [5] и приняли оцененные градиенты глубины ключевых кадров в качестве ограничения для обеспечения глобальной согласованности трехмерной реконструкции.


=== Локализация на основе методов глубокого обучения без учителя

Основная проблема в системах оценки позы с учителем - это необходимость наличия большого количества данных с аннотированной достоверной координатой для всего набора данных при обучении.
В настоящее время размер наборов данных с аннотированной достоверной информацией ограничен, а их сбор является дорогой и времязатратной процедурой. Это препятствует дальнейшему совершенствованию систем обучения с учителем. 

Недавно, для обучения системы без учителя, неконтролируемые методы DL были успешно применены для оценки глубины. Реализация была построена на технике искажения изображений «пространственный трансформер» [28]. 

Метод из [11] проводит оценку глубины на основе глубокого обучения без учителя используя фотометрическое ограничение в стерео парах изображений исходящее из фиксированного взаимного положения пары камер. 
Реализация системы, основанной на обученной с нуля без учителя сети представленые в работе [11] превосходят результаты некоторых методов обеченных по размеченным данным с точки зрения точности оценки глубины. 

В работе [29] показан метод преобразования видео из 2D в 3D обученный без учителя. 
В работе [30] показан улучшеннный метод [11] использующие наложение левого и правого стерео изображений.

SfMLearner [31]  использует последовательность моно изображений, проводит попарное совмещение изображений с целью одновременной оценки глубины и определения движения камеры. Метод также использует обучение без учителя. Однако из-за работы с моно кадрами, в предполагаемой карте глубины нет информации о масштабе. SfM-Net [32] добавляет маску движения к фотометрическую невязку пары изображений. Метод определяет оптический поток между изображениями, строит карту глубины и определяет перемещение камеры. 

Метод визуальной одометрии [33] на основе обучения без учителя использует стереоизображения для обучения и монокулярные изображения для тестирования системы, система пытается восстановить масштаб в моно изображениях. 

Алгоритмы визуальной локализации в большинстве содержат известные модули - как то модуль фильтрации входа, локализации, часть алгоритма для определения замыкания петли и методы оптимизации карты.

Полное решение методов SLAM на основе глубокого обучения это нестандартная задача у которой еще мало качественных решений.

// Можно найти реализации отдельных элементов или компонентов SLAM на основе глубокого обучения как 
// фильтрация выбросов, обнаружение циклов в карте [34], [35], оптимизация графа карты [36],распознавание места и обнаружение замыкания петли [37], [38]. 

Отказ от выбросов, обнаружение замыкания цикла [34], [35] и оптимизация графа положений камеры [36] являются очень важными компонентами для визуальных систем SLAM для уменьшения совместной ошибки навигации, то есть увеличения точности метода. 
Всего несколько работ представили отдельные элементы систем визуальной одометрии на основе DL. Методы на основе DL достигли большого успеха в распознавании места и обнаружении замыкания петель [37], [38]. Можно сказать, что важно сочетать методы обнаружения петель на основе DL с системами визуальной одометрии на основе DL для повышения точности.

Если отдельные компоненты SLAM показывают хорошую производительность, то значительно проще будет использовать комбинацию методов традицинного SLAM и методов глубокого обучения. Подобные модификации были представлены в работах DynaSLAM, DOT.

Таким образом, неконтролируемые методы DL (методы без учителя, методы полного обучения с нуля) представляют новое
направление исследований в области исследования визуального SLAM, потенциально обеспечивая дальнейшее повышение производительности визуальных SLAM-систем. 

На основе известных работ можно сказать о равнозначности подходов глубокого обучения и методов классического SLAM в задаче навигации. Тем не менее есть значительные отличия в подходе к использованию методов глубокого обучения в задаче навигации. Такие методы гарантируют более стабильную работу в большинстве визуальных условий окружения, но зачастую требуют специального оборудования и требовательны к производительности исполнительного устройства.
Идеальным сценарием применения нейросетевых методов представляется их совместное использование с классическими методами, то есть своего рода поддержка обратной совместимости. 
В этом плане возможно совместное обучение двух систем, классического SLAM и нейросетевого. При этом возможно либо дублирование системы локализации и навигации, или попытка улучшения точности навигации за счет совместного обучения. 
Фактически, если нет внешнего испочника информации с гарантированными данными о точности решения, то невозможно определить более точное решение между конкурирующими методами классического и нейросетевого SLAM, таким образом, однозначно гарантировать без дополнительных затрат можно только поддержку обратной совместимости между методами и построенными картами.


== Обзор системы DeepSLAM


Согласно схеме тестирования DeepSLAM на рис. 1, обученные Tracking-Net, Mapping-Net и Loop-Net можно рассматривать как интерфейс, дающий граф положений камеры (граф поз) из последовательности монокулярных изображений. 

В частности, Tracking-Net - это архитектура RCNN, построенная из CNN-части VGGNet [39] и рекуррентной нейронной сети (RNN) для оценки поз и неопределенностей, Mapping-Net - это сеть с архитектурой энкодер-декодер для создания плотных карт глубины, Loop-Net создает разреженные векторы признаков для обнаружения замыкания цикла. 

Между тем, оптимизация графа поз (граф карты, где вершина представляет собой определенную координату камеры в пространстве в определенный момент времени в выбранной системе координат - соответственно метрический масштаб представления данных в карте) используется для уточнения поз в качестве задней части.


image::5-1-2022-02-34-39-AM.png[] 
// Рис. 2. 
Схема обучения предлагаемой системы DeepSLAM. Используются стереоизображения для обучения системы, чтобы восстановить масштабную информацию окружающей среды, аналогичную той, которая используется при обучении. Потери пространственного изображения между парой стереоизображений и временные потери изображения между парой изображений последовательности формулируются для обучения сетей. Карта ошибок, созданная системой, используется в качестве масок потерь для отклонения выбросов. Неопределенность, создаваемая системой, также используется для обучения сетей.
// Fig. 2. Training scheme of the proposed DeepSLAM system. We use stereo images to train the system in order to recover the scale information
// of the environment, which is similar to ones used in training. The spatial image losses between a stereo image pair and the temporal image losses
// between a sequence image pair are formulated to train the networks. The error map produced from the system is used as the loss masks for outlier
// rejection. The uncertainty produced from the system is also used to train the networks.

Схема обучения DeepSLAM показана на рис. 2. Tracking-Net и Mapping-Net обучаются без учителя с использованием пар стереоизображений и геометрических потерь. 

Целью использования пар стереоизображений вместо монокулярных для обучения является восстановление масштабной информации окружающей среды. В ходе экспериментов авторами DeepSLAM было обнаружено, что информацию о масштабе можно восстановить, если условия обучения и тестирования схожи. 
Loop-Net - это предварительно обученная CNN для определения замыканий петель.
Как показано на рис. 2, применены как пространственная, так и временная геометрическая согласованность последовательностей стереоизображений, чтобы сформулировать функцию потерь. 

Пространственная геометрическая согласованность представляет собой геометрическую проективную связь между соответствующими точками в парах левого и правого изображений, тогда как временная геометрическая согласованность представляет собой геометрическую проективную связь между соответствующими точками в двух последовательных монокулярных изображениях. Используя эти ограничения для построения функций потерь и минимизируя их все вместе, сети учатся оценивать масштабированные позы с 6 степенями свободы и карты глубины сквозным неконтролируемым образом.

Детали различных функций потерь, используемых для обучения не приводятся в документе, приводится только сравнение результатов применения конкретного метода и общие выводы по использованию этого метода.



=== Применение пространственно-временных геометрических ограничений для обучения системы SLAM без учителя


image::5-1-2022-03-37-12-AM.png[]
Пространственно-временных геометрических ограничения, используемые для определения соответствующих функций потерь



==== Функция потерь пространственной согласованности пары стереоизображений

Функция потерь пространственной согласованности изображений использует геометрические ограничения между стереоизображениями, чтобы позволить Mapping-Net создавать значимые карты глубины, которые содержат информацию о масштабе. Для пары стереоизображений каждый перекрывающийся пиксель i в одном изображении может найти свое соответствие в другом изображении с горизонтальным расстоянием Hi [11]. Учитывая его значение глубины Di, расстояние Hi можно рассчитать по формуле
Hi = Bf / Di (1),

где B - базовая линия стереокамеры, а f - фокусное расстояние. Следовательно, используя предсказанную карту глубины Di из Mapping-Net, карта расстояний H может быть сгенерирована для всего изображения. На основе H мы можем синтезировать новое изображение, искажая изображение из другого с помощью пространственного преобразователя [28]. 

Функция потерь пространственной согласованности для оценки качества синтезированного изображения определяется как смешанная сумма показателя структурного сходства (SSIM) пары изображений [40], [41] с весом λs и линейной нормы (L1) попиксельной разницы между изображениями (синтезированные левое и правое изображения из исходного правого изображения Ir и левого изображения Il, соответственно) с весом (1 - λs).

// В виде- суммы Il × и Ir × - это синтезированные левое и правое изображения из исходного правого изображения Ir и левого изображения Il, соответственно.
// Потери фотометрической согласованности слева и справа можно построить как
// Lp = Σ λsfs (Il, I ×) + (1 - λs) ǁIl - I × ǁ (2)


image::5-1-2022-02-54-01-AM.png[]

Отдельно определяются функции потерь для согласованности диспаратности (гладкость градиента освещенности изображения) и согласованности положений камеры.

//       1) Потеря согласованности диспаратности: карта диспаратности определяется
// Q = H × w (4)
// где w - ширина изображения. Следовательно, оцененные карты левого и правого диспаратности также могут быть ограничены посредством H. Обозначим Q1 и Qr как левые и правые карты диспаратности соответственно. Подобно потере фотометрической согласованности, мы можем использовать H для синтеза
// Q × l и Qr × из Qr и Ql соответственно. Используя эти карты диспаратности, потери согласованности диспаратности могут быть построены как

Функция потерь согласованности позы: если последовательности левого и правого изображений используются отдельно для оценки преобразований с 6 степенями свободы движения камеры через сеть для определения положения камеры (модуль tracking), в идеале эти относительные перемещения должны быть приблизительно точными, а повороты должны быть точно такими же. Следовательно, различия между двумя группами оценок позы составляют функцию потерь согласованности позы слева и справа.

Фактически можно представить функцию потерь как сумму невязок по расстоянию и по углу с определенным коэффициентом. Нет прямой возможности дать точное значение для коэффициента смешивания, поскольку угол и координата это разные, несравнимые величины измерения. Но в целом данный подход является общепринятым. Для более правильной оценки можно применять геометрию кватернионов, но в случае работы с изображениями это потребует дополнительных преобразований для всех пикселов каждого кадра, что создает дополнительные проблемы при вычислениях.

Система определяет и использует временную функцию потерь для последовательности монокулярных изображений.

Временная функция потерь использует геометрические ограничения (а именно движение камеры) между несколькими видами последовательности монокулярных изображений, чтобы позволить Mapping-Net создавать значимые карты глубины, а Tracking-Net - оценивать движение камеры.

Как показано на рис. 3, архитектура RCNN обеспечивает корреляцию между двумя последовательными монокулярными изображениями. Метод включает в себя функциии потерь фотометрической согласованности и трехмерной геометрической регистрации.

- Функция потерь фотометрической согласованности: В отличие от предыдущей потери фотометрической согласованности пары стереоизображений, фотометрические потери здесь сосредоточены на временной информации в последовательности монокулярных изображений. Для каждой пары изображений с некоторыми перекрытиями сцен мы можем получить их синтезированные изображения с помощью пространственной сети трансформера [28], при этом кадры для анализа не обязательно идут подряд.

- Функция потерь трехмерной геометрической реконструкции: геометрические потери используются для ограничения и оценки преобразований путем рассмотрения трехмерных облаков точек. Это похоже на итерационный метод определения ближайшей точки (ICP), хорошо известный метод выравнивания облаков точек. В DeepSLAM также используется эта функция потерь для оценки правильност реконструкции положения камеры.


=== Оценка неопределенности решения и фильтрация выбросов

Оценка неопределенности и отклонение выбросов очень важны в системах SLAM. Для оценки неопределенности, в методах регрессии положения камеры с учителем либо применяют метод выборки (Dropout) [14], либо добавляют коэффициент баланса к
динамическим объекты в сцене.
сеть как модель смеси [15] для получения неопределенности оценки позы. В отличие от этих контролируемых методов, DeepSLAM может создавать карты прогнозируемых фотометрических ошибок Ek, Ek + 1 и карты прогнозируемых геометрических 
// Это будет подробно рассмотрено в Разделе VI-D.

Для определения точности реконструкции геометрической и фотометрической ошибками вводится функция потерь как норма первого порядка между ожидаемым и реальным значением неопределенности глубины.

Аппроксимация ожидаемого значения производится с использованием сигмоидальных функций и нормализующего фактора.
Неопределенность оценивается с помощью Tracking-Net и представляется в построение локального графа (этап построения локальной карты). 

Можно интуитивно понять, что неопределенность реконструкции мала, когда предполагаемые позы и карты глубины 
достаточно точные, чтобы уменьшить фотометрические и геометрические ошибки. 
В реальных условиях фотометрические и геометрические потери могут быть искажены динамическими объектами. Поэтому в DeepSLAM используются динамические маски для карт ошибок в предыдущих временных потерях. 
В DeepSLAM предлагается новый метод построения побитовых масок, чтобы отбросить выброс во время обучения. 

Маски строятся сооответственно процентного отношения (перцентиля/вероятности появления ошибки) в соответствии со значениями ошибок на картах ошибок. 
// В частности, на основе неопределенности σk, k + 1, процентиля qth от пиксели
// определяется

Сгенерированные побитовые маски не только автоматически адаптируются к уровню шума входного сигнала но также позволяют фильтровать динамические объекты в сцене (без использования отдельного этапа сегментации изображения, что является значительным преимуществом по сравнению с любым классическим методом).


== Построение графа положений камеры и оптимизация графа

Оптимизация графа используется в системах SLAM для уменьшения совокупной ошибки навигации путем совместной коррекции смещения положения камеры и самой карты. 

В системе DeepSLAM также выполняется оптимизация графа карты с локальными и глобальными связями положений камеры.

Граф локальных поз строится на короткой последовательности последовательных изображений как прямой результат рекуррентной модели Tracking-Net с учетом последовательности изображений, то есть граф локальных поз строится из последовательных кадров изображений.
Замыкания глобальных циклов обнаруживаются Loop-Net по историческим изображениям, которые обычно не являются последовательными.

image::5-1-2022-05-12-27-AM.png[]
// Рис. 4. 
Граф поз с локальными и глобальными связями. Пунктирные линии представляют глобальные петли, обнаруженные с помощью Loop-Net, тогда как сплошные линии представляют локальные петли, созданные с помощью Tracking-Net. Здесь в качестве примера показан локальный граф с длиной последовательности изображений 5.


=== Локальный граф положений камеры на основе рекуррентной сети RCNN

Архитектура RCNN Tracking-Net может определить взаимосвязь между функциями CNN с течением времени по мере движения камеры,
и соответственно моделировать динамику движения камеры из последовательности изображений. 
Следовательно, на основе структуры Tracking-Net можно построить локальный граф карты напрямую. 
// Предполагая, что длина последовательности изображений равна n, каждый раз, когда Tracking-Net может оценить (n 1) относительных поз для построения локального графа поз. 

Пример графа поз, построенного с длиной последовательности 5, показан на рис. 4. По мере того, как камера перемещается во времени, система может постепенно построить граф поз с локальными циклами.



=== Обнаружение глобальной петли на основе CNN

Для построения глобального графа карты, используется Loop-Net для распознавания места и обнаружения совпадений (замыканий) между несоседними кадрами. 

Loop-Net в системе DeepSLAM - это модель CNN, предварительно обученная на наборе данных ImageNet для распознавания объектов, поскольку она показала хорошую производительность при обучении представлений. Важно, что для Loop-Net обучение не требуется. Здесь принята архитектура Inception ResNet V2 [43]. 
Loop-Net сопоставляет изображения с векторами признаков для обнаружения замыкания петель. Затем вычисляется косинусное расстояние двух векторов признаков из пары изображений, чтобы обнаружить замыкания цикла.

// dcos = cos (v1, v2) (17)


где v1
и v2
представляют собой векторные представления
th


пара изображений. Когда dcos меньше порогового значения dcos, пара изображений обрабатывается как цикл.
После того, как Loop-Net обнаруживает глобальные петли, мы используем нашу Tracking-Net для вычисления преобразования между обнаруженными парами изображений. Поскольку рекуррентная структура делает Tracking-Net гибким в зависимости от длины последовательности изображений, мы можем использовать длину последовательности 2 для вычисления преобразования позы. Как только глобальный цикл обнаружен, g2o [36] используется как бэкэнд для оптимизации графа поз.



== VI. ЭКСПЕРИМЕНТАЛЬНАЯ ОЦЕНКА
В этом разделе мы демонстрируем производительность отслеживания и отображения предлагаемой системы DeepSLAM. Мы провели оценку точности позы и глубины отдельно, чтобы увидеть, как работает каждая сеть.
Предлагаемый DeepSLAM был разработан с использованием структуры DL TensorFlow и обучен на NVIDIA DGX-1 с Tesla P100. Оптимизатор Adam использовался для обучения сети до 20–30 эпох. Начальная скорость обучения составляла 0,001 и снижалась наполовину на каждую пятую от общего числа итераций. Параметр β1 равен 0,9, а β2 равен 0,99. Длина последовательности
изображений, подаваемых в Tracking-Net, было 5. Размер изображения был 416 × 128. Мы также изменили размер выходных изображений на более высокий


разрешение, чтобы вычислить потери и настроить сети в конце. Для тестирования использовался ноутбук, оснащенный графическим процессором NVIDIA GeForce GTX 980 M и процессором Intel Core i7-6820HK 2,7 ГГц. Память графического процессора, необходимая для Tracking-Net, составляла менее 400 МБ с производительностью в реальном времени 40 Гц. Для Mapping-Net и Loop-Net мы выполняли прогнозирование плотной глубины и обнаружение замыкания цикла каждые пять кадров. Mapping-Net потребовалось около 48 мс для предсказания плотной карты глубины для каждого кадра и около 120 мс для Loop-Net, чтобы закодировать изображение в соответствующий вектор признаков. Tracking-Net, Mapping-Net, Loop-Net и модуль оптимизации графа поз выполнялись в отдельных потоках. Для всей системы он может работать с частотой около 20 Гц. Для повышения эффективности обучения были предприняты некоторые меры по увеличению данных, такие как увеличение левого и правого изображения, увеличение данных вращения и цвет изображения.
увеличение.

== Результаты сравнения точности позиционирования систем визульной одометрии 


=== A. Выступление на точность позы на KITTI
Сначала мы оценили точность нашей системы Deep-SLAM на наборе данных одометрии KITTI [44]. Полная система DeepSLAM включает Tracking-Net с обнаружением замыкания цикла и оптимизацией графиков. Подробные количественные результаты приведены в Таблице I. Мы использовали стандартный метод оценки, предоставленный вместе с набором данных KITTI: средний дрейф (%) трансляционной среднеквадратичной ошибки (RMSE) и средний
вращательный дрейф СКО (◦ / 100 м) на длине 100–800 м. Мы также добавили два метода обучения на основе данных (ESP-VO и
SfMLearner) и трех модельных методов (монокуляр ORB-SLAM, монокуляр VISO2-M и стерео VISO2-S) в таблицу для сравнения. VISO2-M и монокуляр ORB-SLAM не работали с разрешением 416 × 128, и мы использовали входные изображения.

размером 1241 × 376. Для стерео методов также использовался VISO2-S.
входные изображения размером 1241 × 376. Все методы, основанные на обучении


// We first evaluated the accuracy performance of our Deep-
// SLAM system on the KITTI odometry dataset [44]. The full
// system of DeepSLAM includes the Tracking-Net with loop clo-
// sure detection and graph optimization. The detailed quantitative
// results are listed in Table I. We used the standard evaluation
// method provided along with KITTI dataset: average transla-
// tional root-mean-square error (RMSE) drift (%) and average
// rotational RMSE drift ( ◦ /100 m) on length of 100–800 m.
// We also added two data-driven learning methods (ESP-VO and
// SfMLearner) and three model-based methods (monocular ORB-
// SLAM, monocular VISO2-M and stereo VISO2-S) into the table
// for comparison. VISO2-M and monocular ORB-SLAM did not
// work with resolution 416 × 128, and we used input images
// with size 1241 × 376. For stereo methods, VISO2-S also used
// input images with size 1241×376. All learning-based methods
// (DeepSLAM, ESP-VO and SfMlearner) used KITTI sequences
// 00–02, 08, 09 for network training, and KITTI sequences 03–07,
// 10 as the testing datasets. Our DeepSLAM is an unsupervised
// learning method and does not need the ground truth for training.
// In order to show the advantage of unsupervised learning and
// fully draw out the potential of DeepSLAM, we also used KITTI
// sequences 00–02, 08, 09, 11–21 to train the network. The best
// tracking results among learning methods are made in bold.
// As shown in the table, our DeepSLAM outperforms ESP-VO
// and SfMLearner in terms of tracking accuracy. When compared
// with ESP-VO, we used more datasets (KITTI sequences 11–21)
// for network training as our DeepSLAM does not need datasets
// with annotated ground truth. ESP-VO is a supervised learning
// method and it cannot use KITTI sequences 11–21 for training.
// The result indicates that unsupervised learning methods can use
// more datasets for training and make the benefit in performance
// from it. When compared with SfMLearner, the DeepSLAM
// system adopts more carefully designed spatial and temporal
// losses functions and takes RCNN as Tracking-Net architecture.
// The DeepSLAM also outperforms monocular VISO2-M, but its
// performance is not as good as ORB-SLAM and stereo VISO2-
// S as DeepSLAM cannot maintain the local map and global
// map like ORB-SLAM. The estimated trajectories on sequences


Результаты сравнения точности позиционирования систем визульной одометрии представлены в таблице:

image:4-12-2021-14-05-19-PM.png[] 
Средняя ошибка позиционирования каждой системы визульной одометрии на каждой тестовой последовательности



image:4-12-2021-14-05-13-PM.png[] 
Среднее время обработки одного изображения для каждой системы

Поскольку в системе для локализации используется не карта напрямую, а сопоставление позиции с картой через нейронную сеть, точность системы не может быть гарантированно определена.




По изображениям можно определить что монокулярный ORBSLAM дает низкую точность позиционирования в момент инициализации системы. Поскольку монокулярный ORBSLAM не обладает данными о масштабе сцены, привязка к характерным точкам тоже не может быть правильно определена.
Система одометрии осованная на обучении не может точно определить вращение камеры.

Гибридная система DL_Hybrid VO максимально точно определяет положение и вращние камеры.
Система определяет масштаб по последовательноси моно изображений, система использует сети глубокого обучения и контроль оптического пока для точного определения перемещения.


По результатом экспериментов наблюдается точность порядка 3 м на наборе данных KITTI, постоянное смещение маршрута  - абсолютное смещение порядка 5% на длине 100-200м.

Метод при этом демонструрует свою работу независимо от качества освещения и погодных условий.

Таким образом можно говорить о возможном применениии архитектуры, представленной в работе (), для задач локализации и построения карт которые не требовательны к точности.
Например, в качестве вспомогательной системы для контроля точности позиционирования, для релокализации.

Алгоритм также содержит необходимые методы для построения карты глубины, поиска совпадений с картой. 


image::5-1-2022-05-31-07-AM.png[] 

image:5-1-2022-05-29-42-AM.png[] 
Fig. 11. Estimated uncertainty against the corresponding translational
and rotational errors. It shows that the estimated uncertainty values are
strongly correlated with both of them. (a) Seq. 03. (b) Seq. 05.