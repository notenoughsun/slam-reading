
 II-Распознавание места
Обзор Williams et al. [ 13 ] сравнили несколько подходов к распознаванию места и пришли к выводу, что методы, основанные на внешнем виде, то есть сопоставление изображения с изображением, лучше масштабируются в больших средах, чем методы «карта-карта» или «изображение-карта». Среди методов, основанных на внешнем виде, на передний план выходят методы набора слов [ 14 ], такие как вероятностный подход FAB-MAP [ 15 ], из-за их высокой эффективности. DBoW2 [ 5 ] впервые использовал пакеты двоичных слов, полученные из дескрипторов BRIEF [ 16 ], вместе с очень эффективным детектором признаков FAST [ 17 ]. Это сократило более чем на порядок время, необходимое для извлечения признаков, по сравнению с функциями SURF [ 18 ] и SIFT [ 19 ], которые до сих пор использовались в подходах к пакетам слов. Хотя система продемонстрировала свою очень эффективную и надежную работу, использование BRIEF, не зависящее от вращения или масштаба, ограничивало систему траекториями в плоскости и обнаружением петель с аналогичных точек зрения. В нашей предыдущей работе [ 11 ] мы предложили пакет распознавания места слов, построенный на DBoW2 с ORB [ 9 ]. ORB - это двоичные функции, инвариантные к вращению и масштабированию (в определенном диапазоне), что приводит к очень быстрому распознаванию с хорошей инвариантностью к точке обзора. Мы продемонстрировали высокую отзывчивость и надежность распознавателя в четырех различных наборах данных, которым требуется менее 39 мс (включая извлечение признаков) для извлечения кандидата в цикл из базы данных изображений размером 10К. В этой работе мы используем улучшенную версию этого распознавателя мест, использующую информацию о видимости и возвращающую несколько гипотез при запросе к базе данных, а не только наилучшее совпадение.
 II-B ИНИЦИАЛИЗАЦИЯ КАРТЫ


Для монокулярного SLAM чтобы определить положение характерных точек на карте в трехмерном пространстве требуется воостановить глубину на изображении. Существует три известных метода для восстановления глубины в изображении: использование специальной камеры с RGBD сенсором которая напрямую выдает данные глубины в изображении, руконструкция трехмерной сцены по двум жестко связанным камерам (работа в режиме стерео съемки), реконструкция глубины точек по серии кадров с разных направлений.
Таким образом монокулярный SLAM требует особой процедуры для создания начальной карты, потому что глубина не может быть восстановлена ​​из одного изображения.

Восстановление глубины в контексте методов фильтрации, точки могут быть инициализированы с высокой неопределенностью по глубине, используя обратную параметризацию глубины [ 21 ], что позже должно сходиться к реальным положениям характерных точек.
Недавняя полу-плотная работа Engel et al. [ 10 ], следует аналогичному подходу, инициализируя глубину пикселей случайным значением с высокой дисперсией.
Методы инициализации положения точек по двум кадрам либо предполагают локальную планарность сцены [ 4 , 22 ], либо восстанавливают относительную позу камеры из гомографии с использованием метода Faugeras et. al [ 23 ], или вычислить существенную матрицу [ 24 , 25 ], которая моделирует плоские и общие сцены, используя пятибалльный алгоритм Нистера [ 26 ], который требует иметь дело с несколькими решениями.
Оба метода реконструкции плохо ограничиваются при низком параллаксе и страдают от двоякой неоднозначности решения, если все точки плоской сцены находятся ближе к одному из центров камеры [ 27 ].
С другой стороны, если неплоская сцена видна с параллаксом, уникальная фундаментальная матрица может быть вычислена с помощью алгоритма из восьми точек [ 2 ], и относительная поза камеры может быть восстановлена ​​без двусмысленности.
В разделе IV мы представляем новый автоматический подход, основанный на выборе модели между гомографией для плоских сцен и фундаментальной матрицей для неплоских сцен. Статистический подход к выбору модели был предложен Torr et al. [ 28 ]. Исходя из аналогичных соображений, мы разработали эвристический алгоритм инициализации, который учитывает риск выбора фундаментальной матрицы в случаях, близких к вырожденным (т.е. планарная, почти планарная и с низким параллаксом), в пользу выбора гомографии. В плоском случае в целях безопасности мы воздерживаемся от инициализации, если решение имеет двоякую неоднозначность, поскольку может быть выбрано поврежденное решение. Мы откладываем инициализацию до тех пор, пока метод не даст уникальное решение со значительным параллаксом.


 II-C МОНОКУЛЯРНЫЙ SLAM
При разборе методов SLAM необоходимо в первую очередь рассматривать монокулярный SLAM.
Задача монокулярного SLAM изначально была решена с помощью методов фильтрации [ 20 , 29 , 30 , 21 ].
При таком подходе каждый кадр обрабатывается фильтром для совместной оценки местоположения объектов на карте и положения камеры. Он имеет недостатки, заключающиеся в бесполезной трате вычислений при обработке последовательных кадров с небольшим количеством новой информации и накоплении ошибок линеаризации.
С другой стороны, подходы на основе ключевых кадров [ 3 , 4 ] оценивают карту, используя только выбранные кадры (ключевые кадры), что позволяет выполнять более дорогостоящую, но точную оптимизацию настройки пакетов, поскольку отображение не привязано к частоте кадров. Strasdat et. [ 31 ] продемонстрировал, что методы, основанные на ключевых кадрах, более точны, чем фильтрация, при тех же вычислительных затратах.
Наиболее представительной системой SLAM на основе ключевых кадров, вероятно, является PTAM [ 4 ], алгоритм разделяет отслеживание и отображение камеры в параллельных потоках, и успешно работает для приложений дополненной реальности в реальном времени в небольших средах. Точки карты PTAM соответствуют углам FAST, сопоставленным с помощью корреляции фрагментов. Это делает точки полезными только для отслеживания, но не для распознавания места. Фактически, PTAM не обнаруживает большие циклы, и определение перемещения основано только на корреляции сжатых ключевых кадров с низким разрешением, что снижает точность алгоритма покольку учитывает положение точки обзора менее точно.

Монокулярный SLAM без определения глубины изображения обладает проблемой масштаба. По исходному видеопотоку невозможно определить масштаб изображения и расстояние до объетов, следовательно прихлдится корректировать карту после добавления объектов.
Strasdat et. [ 6 ] представили крупномасштабную монокулярную систему SLAM реализующим замыкание петель с помощью оптимизации графа положений камеры и характерных точек с ограничениями 7DoF. Использовние 7DoF ограничений позволяет скорректировать ошибку масштаба в монокулярном SLAM. ORB-SLAM заимствует тип ограничений модели из этой работы,  и реализует замыкание цикла с помощью оптимизации графа позы 7DoF, применяя оптимизацию к выбранной части графа, называемой в алгоритме Essential Graph.

Ранние монокулярные методы применяют локальную оптимизацию графа.
Strasdat et. al [ 7 ] использовал интерфейс PTAM (частичное отслеживание и построение карты), но выполнял отслеживание только на локальной карте, полученной из графа совместной видимости. Strasdat et. al [ 7 ] реализовал серверную модель для непрерывной оптимизации двойного окна, выполняя обновление и оптимизацию графа (BA) во внутреннем окне и обновляя граф во внешнем окне ограниченного размера. Однако такой алгоритм замыкания цикла эффективен только в том случае, если размер внешнего окна достаточно велик, чтобы охватить весь цикл. В ORB-SLAM используется идея локальной карты для построения и дополнения графа поз на основе графа взаимной видимости без внешнего сервера. Другое отличие ORB-SLAM от PTAM состоит в том, что вместо использования определенных характерных точек для обнаружения петель (SURF) выполняется распознавание места в графе для совмещения тех же отслеживаемых и сопоставленных характерных точек, получая необходимую производительность метода локализации и обнаружения петель.

CD-SLAM [ 33 ] - полноценная система SLAM, включающая замыкание циклов, релокализацию при обновлении карты, поддержку работы с крупномасштабными картами и динамическими средами. Однако отсутствует общедоступная реализация  и нет большого количества данных о точности и надежности данного метода.

Визуальная одометрия Song et al. [ 34 ] использует функции ORB для отслеживания и серверную часть BA с временным скользящим окном. Система ORB-SLAM является более универсальной, поскольку содержит методы глобальной релокализации, замыкания циклов и переиспользования карты. Song et al. [ 34 ]  также используют ограничение на фиксированное расстояние от камеры до земли.
Lim et. al [ 25 ], работа, опубликованная после того, как мы представили нашу предварительную версию этой работы [ 12 ], также использует те же функции для отслеживания, отображения и обнаружения петель. Однако выбор BRIEF ограничивает систему траекториями в плоскости.

Если система отслеживает только точки из последнего ключевого кадра аналогично работе Lim et. al [ 25 ], то карта не используется повторно при повторном посещении (аналогично визуальной одометрии) и количество точек на карте будет линейно неограниченно возрастать. ORB-SLAM не имеет такой проблемы, при повторном добавлении точек в карту рост размера карты не происходит, это позволяет использовать метод на больших локациях.

Работа Engel et. [ 10 ], известная как LSD-SLAM, способна строить крупномасштабные полу-плотные карты (в карте содержатся граф характерных точек и часть информации с самих изображений), используя прямые методы (т. е. оптимизацию непосредственно по интенсивности пикселей изображения) вместо решения неплотной системы, то есть совместной оптимизации графа характерных точек. LSD-SLAM может работать в реальном времени, без использования графического процессора, создавая полу-плотную карту с большим количеством потенциальных приложений для робототехники. Тем не менее, качество обнаружения петель и суммарная точность определения местоположения камеры значительно ниже, чем в ORB-SLAM и PTAM.

Между прямым LSD-SLAM и дескрипторными методами (ORB-SLAM, PTAM) находится визуальная одометрия SVO Forster et al. [ 22 ]. Не требуя извлечения элементов из каждого кадра, метод может работать с высокой частотой кадров, получая впечатляющие результаты в квадракоптерах. Обнаружение петель не выполняется, и реализация в основном предназначена для камер, смотрящих вниз.


Стратегия выбора ключевых кадров это отдельная задача в SLAM по данным камеры, никакие существующие решения задачи SLAM не выполняют обновление и оптимизацию графа со всеми точками и всеми кадрами. Работа Strasdat et al. [ 31 ] показывает, что наиболее экономичный подход - сохранить как можно больше точек, сохраняя только неизбыточные ключевые кадры. Подход PTAM основан на очень осторожной вставке ключевых кадров в набор для опртимизации, чтобы избежать чрезмерного роста вычислительной сложности. Эта ограничительная политика вставки ключевых кадров приводит к сбою отслеживания в сложных условиях исследования. У ORB-SLAM применена стратегия выживания наиболее соответствующих остальному набору кадров, что обеспечивает надежность алгоритма в сложных сценариях. Алгоритм умеет добавлять и удалять кадры из задачи оптимизации, что дает избежание дополнительных затрат.


[1] B. Triggs, P. F. McLauchlan, R. I. Hartley, and A. W. Fitzgibbon, “Bundle adjustment — a modern synthesis,” in Vision algorithms: theory and practice, 2000, pp. 298–372.
[2] R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision, 2nd ed.   Cambridge University Press, 2004.
[3] E. Mouragnon, M. Lhuillier, M. Dhome, F. Dekeyser, and P. Sayd, “Real time localization and 3d reconstruction,” in Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, vol. 1, 2006, pp. 363–370.
[4] G. Klein and D. Murray, “Parallel tracking and mapping for small AR workspaces,” in IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR), Nara, Japan, November 2007, pp. 225–234.
[5] D. Gálvez-López and J. D. Tardós, “Bags of binary words for fast place recognition in image sequences,” IEEE Transactions on Robotics, vol. 28, no. 5, pp. 1188–1197, 2012.
[6] H. Strasdat, J. M. M. Montiel, and A. J. Davison, “Scale drift-aware large scale monocular SLAM.” in Robotics: Science and Systems (RSS), Zaragoza, Spain, June 2010.
[7] H. Strasdat, A. J. Davison, J. M. M. Montiel, and K. Konolige, “Double window optimisation for constant time visual SLAM,” in IEEE International Conference on Computer Vision (ICCV), Barcelona, Spain, November 2011, pp. 2352–2359.
[8] C. Mei, G. Sibley, and P. Newman, “Closing loops without places,” in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Taipei, Taiwan, October 2010, pp. 3738–3744.
[9] E. Rublee, V. Rabaud, K. Konolige, and G. Bradski, “ORB: an efficient alternative to SIFT or SURF,” in IEEE International Conference on Computer Vision (ICCV), Barcelona, Spain, November 2011, pp. 2564–2571.
[10] J. Engel, T. Schöps, and D. Cremers, “LSD-SLAM: Large-scale direct monocular SLAM,” in European Conference on Computer Vision (ECCV), Zurich, Switzerland, September 2014, pp. 834–849.
[11] R. Mur-Artal and J. D. Tardós, “Fast relocalisation and loop closing in keyframe-based SLAM,” in IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China, June 2014, pp. 846–853.
[12] ——, “ORB-SLAM: Tracking and mapping recognizable features,” in MVIGRO Workshop at Robotics Science and Systems (RSS), Berkeley, USA, July 2014.
[13] B. Williams, M. Cummins, J. Neira, P. Newman, I. Reid, and J. D. Tardós, “A comparison of loop closing techniques in monocular SLAM,” Robotics and Autonomous Systems, vol. 57, no. 12, pp. 1188–1197, 2009.
[14] D. Nister and H. Stewenius, “Scalable recognition with a vocabulary tree,” in IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), vol. 2, New York City, USA, June 2006, pp. 2161–2168.
[15] M. Cummins and P. Newman, “Appearance-only SLAM at large scale with FAB-MAP 2.0,” The International Journal of Robotics Research, vol. 30, no. 9, pp. 1100–1123, 2011.
[16] M. Calonder, V. Lepetit, C. Strecha, and P. Fua, “BRIEF: Binary Robust Independent Elementary Features,” in European Conference on Computer Vision (ECCV), Hersonissos, Greece, September 2010, pp. 778–792.
[17] E. Rosten and T. Drummond, “Machine learning for high-speed corner detection,” in European Conference on Computer Vision (ECCV), Graz, Austria, May 2006, pp. 430–443.
[18] H. Bay, T. Tuytelaars, and L. Van Gool, “SURF: Speeded Up Robust Features,” in European Conference on Computer Vision (ECCV), Graz, Austria, May 2006, pp. 404–417.
[19] D. G. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004.
[20] A. J. Davison, I. D. Reid, N. D. Molton, and O. Stasse, “MonoSLAM: Real-time single camera SLAM,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29, no. 6, pp. 1052–1067, 2007.
[21] J. Civera, A. J. Davison, and J. M. M. Montiel, “Inverse depth parametrization for monocular SLAM,” IEEE Transactions on Robotics, vol. 24, no. 5, pp. 932–945, 2008.
[22] C. Forster, M. Pizzoli, and D. Scaramuzza, “SVO: Fast semi-direct monocular visual odometry,” in Proc. IEEE Intl. Conf. on Robotics and Automation, Hong Kong, China, June 2014, pp. 15–22.
[23] O. D. Faugeras and F. Lustman, “Motion and structure from motion in a piecewise planar environment,” International Journal of Pattern Recognition and Artificial Intelligence, vol. 2, no. 03, pp. 485–508, 1988.
[24] W. Tan, H. Liu, Z. Dong, G. Zhang, and H. Bao, “Robust monocular SLAM in dynamic environments,” in IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Adelaide, Australia, October 2013, pp. 209–218.
[25] H. Lim, J. Lim, and H. J. Kim, “Real-time 6-DOF monocular visual SLAM in a large-scale environment,” in IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China, June 2014, pp. 1532–1539.
[26] D. Nistér, “An efficient solution to the five-point relative pose problem,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 26, no. 6, pp. 756–770, 2004.
[27] H. Longuet-Higgins, “The reconstruction of a plane surface from two perspective projections,” Proceedings of the Royal Society of London. Series B. Biological Sciences, vol. 227, no. 1249, pp. 399–410, 1986.
[28] P. H. Torr, A. W. Fitzgibbon, and A. Zisserman, “The problem of degeneracy in structure and motion recovery from uncalibrated image sequences,” International Journal of Computer Vision, vol. 32, no. 1, pp. 27–44, 1999.
[29] A. Chiuso, P. Favaro, H. Jin, and S. Soatto, “Structure from motion causally integrated over time,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 24, no. 4, pp. 523–535, 2002.
[30] E. Eade and T. Drummond, “Scalable monocular SLAM,” in IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, New York City, USA, June 2006, pp. 469–476.
[31] H. Strasdat, J. M. M. Montiel, and A. J. Davison, “Visual SLAM: Why filter?” Image and Vision Computing, vol. 30, no. 2, pp. 65–77, 2012.
[32] G. Klein and D. Murray, “Improving the agility of keyframe-based slam,” in European Conference on Computer Vision (ECCV), Marseille, France, October 2008, pp. 802–815.
[33] K. Pirker, M. Ruther, and H. Bischof, “CD SLAM-continuous localization and mapping in a dynamic world,” in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), San Francisco, USA, September 2011, pp. 3990–3997.
[34] S. Song, M. Chandraker, and C. C. Guest, “Parallel, real-time monocular visual odometry,” in IEEE International Conference on Robotics and Automation (ICRA), 2013, pp. 4698–4705.
[35] P. F. Alcantarilla, J. Nuevo, and A. Bartoli, “Fast explicit diffusion for accelerated features in nonlinear scale spaces,” in British Machine Vision Conference (BMVC), Bristol, UK, 2013.
[36] X. Yang and K.-T. Cheng, “LDB: An ultra-fast feature for scalable augmented reality on mobile devices,” in IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2012, pp. 49–57.
[37] R. Kuemmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard, “g2o: A general framework for graph optimization,” in IEEE International Conference on Robotics and Automation (ICRA), Shanghai, China, May 2011, pp. 3607–3613.
[38] J. Sturm, N. Engelhard, F. Endres, W. Burgard, and D. Cremers, “A benchmark for the evaluation of RGB-D SLAM systems,” in IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vilamoura, Portugal, October 2012, pp. 573–580.
[39] M. Smith, I. Baldwin, W. Churchill, R. Paul, and P. Newman, “The new college vision and laser data set,” The International Journal of Robotics Research, vol. 28, no. 5, pp. 595–599, 2009.
[40] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, “Vision meets robotics: The KITTI dataset,” The International Journal of Robotics Research, vol. 32, no. 11, pp. 1231–1237, 2013.
[41] V. Lepetit, F. Moreno-Noguer, and P. Fua, “EPnP: An accurate O(n) solution to the PnP problem,” International Journal of Computer Vision, vol. 81, no. 2, pp. 155–166, 2009.
[42] B. K. P. Horn, “Closed-form solution of absolute orientation using unit quaternions,” Journal of the Optical Society of America A, vol. 4, no. 4, pp. 629–642, 1987.
[43] F. Endres, J. Hess, J. Sturm, D. Cremers, and W. Burgard, “3-d mapping with an rgb-d camera,” IEEE Transactions on Robotics, vol. 30, no. 1, pp. 177–187, 2014.
[44] R. A. Newcombe, S. J. Lovegrove, and A. J. Davison, “DTAM: Dense tracking and mapping in real-time,” in IEEE International Conference on Computer Vision (ICCV), Barcelona, Spain, November 2011, pp. 2320–2327.
[45] S. Lovegrove, A. J. Davison, and J. Ibanez-Guzmán, “Accurate visual odometry from a rear parking camera,” in IEEE Intelligent Vehicles Symposium (IV), 2011, pp. 788–793.
[46] P. H. Torr and A. Zisserman, “Feature based methods for structure and motion estimation,” in Vision Algorithms: Theory and Practice.   Springer, 2000, pp. 278–294.
[47] R. Mur-Artal and J. D. Tardos, “Probabilistic semi-dense mapping from highly accurate feature-based monocular SLAM,” in Robotics: Science and Systems (RSS), Rome, Italy, July 2015.
[48] H. Strasdat, “Local Accuracy and Global Consistency for Efficient Visual SLAM,” Ph.D. dissertation, Imperial College, London, October 2012.
